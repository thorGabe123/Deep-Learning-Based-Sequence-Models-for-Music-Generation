{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import processing\n",
    "import models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(DISCRETIZATION=namespace(PITCH_RES=128,\n",
       "                                   DYN_RES=128,\n",
       "                                   LENGTH_RES=400,\n",
       "                                   TIME_RES=400,\n",
       "                                   CHANNEL_RES=128,\n",
       "                                   TEMPO_RES=300),\n",
       "          RESOLUTION=namespace(BAR_RES=12),\n",
       "          MODEL_VALUES=namespace(TEST_RATIO=0.2,\n",
       "                                 BATCH_SIZE=8,\n",
       "                                 BLOCK_SIZE=252,\n",
       "                                 N_EMBD=128,\n",
       "                                 N_HEAD=8,\n",
       "                                 N_LAYER=8,\n",
       "                                 FEEDFORWARD_DIM=2048,\n",
       "                                 DROPOUT=0.01,\n",
       "                                 EPOCHS=200,\n",
       "                                 EVAL_INTERVAL=100,\n",
       "                                 SAVE_INTERVAL=500,\n",
       "                                 LEARNING_RATE=0.1,\n",
       "                                 EVAL_ITERS=200,\n",
       "                                 DEVICE='cuda',\n",
       "                                 GENERATED_EVENT_LENGTH=300,\n",
       "                                 METADATA_DIMS=namespace(composer=8)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configs.transformer as cm\n",
    "cm.CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = processing.get_train_test_dataloaders('F:\\\\GitHub\\\\dataset\\\\np_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, test_dataloader, criterion,device)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (src, trg, metadata) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 36\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), trg\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\models\\simple_mamba.py:89\u001b[0m, in \u001b[0;36mMamba.forward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_ids)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 89\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f(x)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\models\\simple_mamba.py:173\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m        x: shape (b, l, d)    (See Glossary at top for definitions of b, l, d_in, n...)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "# Assuming processing.py exists and contains get_train_test_dataloaders\n",
    "import processing  # Make sure you have this file\n",
    "import models\n",
    "\n",
    "# Data loading\n",
    "train_dataloader, test_dataloader = processing.get_train_test_dataloaders('F:\\\\GitHub\\\\dataset\\\\np_dataset')\n",
    "\n",
    "# Model Configuration\n",
    "args = models.ModelArgs(\n",
    "    d_model=128, # Example, adjust as needed\n",
    "    n_layer=4, # Example, adjust as needed\n",
    "    vocab_size=VOCAB_SIZE, # Example, adjust as needed\n",
    "    d_state=64, # Example, adjust as needed\n",
    "    expand=4, # Example. adjust as needed\n",
    "    dt_rank = 8, # Example. adjust as needed\n",
    ")\n",
    "model = models.Mamba(args)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4) # Example learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10  # Example number of epochs\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(src)\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), trg.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_dataloader, optimizer, criterion, device)\n",
    "    val_loss = evaluate(model, test_dataloader, criterion,device)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_mamba_model.pth\")\n",
    "\n",
    "print(\"Training complete. Model saved to trained_mamba_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-10.8888,  -4.0384,  -4.9351,  ...,  10.7160,  19.7741, -11.4051],\n",
       "         [  5.2334, -10.9134, -22.3910,  ...,  19.3346,  -4.5296, -12.8813],\n",
       "         [-13.6919,  -3.8146, -16.1524,  ...,   8.9366,  13.6288,   3.0248],\n",
       "         ...,\n",
       "         [ -2.5006,   7.1041,  11.4404,  ..., -26.6092,   2.2654, -22.3841],\n",
       "         [ -9.7289, -12.7942, -10.5393,  ...,  22.8997,   6.4594,   7.4741],\n",
       "         [ -0.1105, -21.6887,  10.0519,  ...,  -9.6944,  -3.1796,   3.0747]],\n",
       "\n",
       "        [[  7.7965, -16.1623, -18.8815,  ...,   6.3841,  15.5585,  18.3863],\n",
       "         [  3.5721,   3.8034,  15.9112,  ...,   1.1973,  20.2115,  14.3474],\n",
       "         [-23.1184,  -2.3423,   4.4069,  ...,   0.2315,   7.3398,  -4.8607],\n",
       "         ...,\n",
       "         [ -1.6749,   7.5199,  11.6485,  ..., -25.9470,   1.9286, -23.5073],\n",
       "         [ -4.2561,   8.3175,   9.4181,  ...,  -0.8406,  14.4761, -15.4855],\n",
       "         [  5.0381,   1.5632, -16.7492,  ...,  -4.4936,   2.5702,  -7.0694]],\n",
       "\n",
       "        [[ -2.4788,   1.2746, -12.5283,  ...,  -9.3525, -10.7720,  13.6061],\n",
       "         [ 21.2612,  -5.5331,  17.5546,  ...,  13.5364,  15.1482,   0.4217],\n",
       "         [  5.0062, -16.8808, -12.5508,  ...,  -5.9159, -14.4714,   1.0851],\n",
       "         ...,\n",
       "         [  9.0154,  10.7362, -10.5771,  ...,  -1.8654,   8.2548,  -5.0016],\n",
       "         [ -4.4206,   7.9789,  10.0432,  ...,  -1.9769,  15.6005, -14.2135],\n",
       "         [-11.8276,   4.2669,  -0.2458,  ...,  23.9813,   2.7357,  18.6872]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "    src\n",
    "model(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:\\\\GitHub\\\\dataset\\\\midi_dataset\\\\tokenizations.json', 'r') as f:\n",
    "    tokenizations = json.load(f)\n",
    "METADATA_VOCAB_SIZE = tokenizations['VOCAB_SIZE']\n",
    "# vocab_size, n_embd, n_layer, n_heads, block_size, dropout, device\n",
    "model = models.Transformer(VOCAB_SIZE, N_EMBD, N_LAYER, N_HEAD, BLOCK_SIZE, DROPOUT, DEVICE)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = EPOCHS\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "        # Forward pass\n",
    "        output = model(src)\n",
    "        # print(output.shape)\n",
    "        # Reshape output and target for loss calculation\n",
    "        output = output.reshape(-1, VOCAB_SIZE)  # Flatten the output to [batch_size * seq_len, vocab_size]\n",
    "        trg = trg.view(-1)  # Flatten the target to [batch_size * seq_len]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Validation loop (optional)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, metadata in test_dataloader:\n",
    "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "            output = model(src, metadata)\n",
    "            output = output.reshape(-1, VOCAB_SIZE)\n",
    "            trg = trg.view(-1)\n",
    "            val_loss += criterion(output, trg).item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 259, 1057,  259, 1483, 1483, 1483, 1185, 1185,  259, 1483, 1483, 1483,\n",
       "        1057, 1447,  259, 1483, 1483, 1483, 1185, 1185,  259,  657, 1483, 1483,\n",
       "        1185, 1185,  259,  657, 1483, 1483,  257, 1057, 1057, 1483, 1057, 1483,\n",
       "        1185,  259,  259, 1483,  657, 1483, 1185, 1057,  259,  657, 1483, 1483,\n",
       "        1185, 1057,  259,  657, 1483, 1483, 1185,  257,  259,  657,  657, 1483,\n",
       "         259, 1185,  259,  657, 1483, 1483, 1057,  257,  259, 1483, 1483, 1483,\n",
       "        1185, 1185,  259, 1483, 1483, 1483, 1185, 1057,  259, 1483, 1483, 1483,\n",
       "        1185, 1057,  259,  657, 1057, 1483, 1185, 1185,  259,  657,  657, 1483,\n",
       "        1185, 1057,  259,  657, 1483, 1483, 1057,  257,  259,  657, 1483, 1483,\n",
       "         257, 1057, 1185,  657, 1057, 1483, 1185, 1185,  259,  657,  657, 1483,\n",
       "        1185, 1057,  259,  657, 1483, 1483, 1185, 1185,  259,  657, 1483, 1483,\n",
       "        1057, 1057,  259,  657, 1483, 1483, 1185, 1185,  259,  657, 1483, 1483,\n",
       "        1185, 1057,  259,  657,  657, 1483, 1185, 1057,  259,  657, 1483, 1483,\n",
       "        1185, 1057,  259,  657, 1483, 1483, 1185, 1057, 1447,  657, 1057, 1483,\n",
       "        1185, 1057,  259,  657, 1057, 1483,  257, 1185,  259,  657, 1057, 1483,\n",
       "        1185, 1447,  259,  657, 1057, 1483, 1185, 1185,  259,  657, 1057, 1483,\n",
       "         257, 1057, 1185,  657, 1057, 1483, 1185,  259,  259,  657,  657, 1483,\n",
       "        1185, 1057,  259,  657, 1483, 1483, 1185, 1057,  259,  657,  657, 1483,\n",
       "        1185,  259,  259,  657, 1483, 1483, 1185, 1185,  259,  657, 1483, 1483,\n",
       "        1185, 1185,  259,  657, 1483, 1483, 1057, 1057,  259,  657, 1483, 1483,\n",
       "        1185, 1185,  259,  657, 1483, 1483,  259, 1057, 1057,  657, 1057, 1483],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "        # Forward pass\n",
    "        output = model(src, metadata)\n",
    "output.argmax(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1485 artists>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flattened_tensor = src.flatten()\n",
    "bins = VOCAB_SIZE\n",
    "hist = torch.histc(flattened_tensor.int(), bins=bins, min=0, max=VOCAB_SIZE)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(bins), hist.cpu().int().numpy(), width=1, align='center', color='blue', edgecolor='black')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
