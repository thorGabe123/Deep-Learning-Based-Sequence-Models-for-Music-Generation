{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mixed dtype (CPU): all inputs must share same datatype.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mnew_model(model_type)\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m train\u001b[38;5;241m.\u001b[39mtrain(model, model_type)\n",
      "File \u001b[1;32mc:\\Users\\min\\Documents\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\train.py:70\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, type)\u001b[0m\n\u001b[0;32m     67\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (src, trg, metadata) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 70\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(src)\n\u001b[0;32m     71\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m.\u001b[39mvocab_size)  \u001b[38;5;66;03m# Flatten the output to [batch_size * seq_len, vocab_size]\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the target to [batch_size * seq_len]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\Documents\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\models\\xlstm\\model_xlstm.py:29\u001b[0m, in \u001b[0;36mxLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m x_original \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 29\u001b[0m      x \u001b[38;5;241m=\u001b[39m l(x) \u001b[38;5;241m+\u001b[39m x_original\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\Documents\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\models\\xlstm\\sLSTMblock.py:51\u001b[0m, in \u001b[0;36msLSTMblock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[0;32m     53\u001b[0m     x_conv \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msilu( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv( x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) )\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) ) )\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# start sLSTM\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2545\u001b[0m     )\n\u001b[1;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlayer_norm(\u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mixed dtype (CPU): all inputs must share same datatype."
     ]
    }
   ],
   "source": [
    "import train\n",
    "import torch\n",
    "model_type = 'xlstm'\n",
    "model = train.new_model(model_type)\n",
    "model.to('cpu')\n",
    "train.train(model, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (src, trg, metadata) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 19\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(src\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     20\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m.\u001b[39mvocab_size)  \u001b[38;5;66;03m# Flatten the output to [batch_size * seq_len, vocab_size]\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the target to [batch_size * seq_len]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\Documents\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\models\\xlstm\\model_xlstm.py:29\u001b[0m, in \u001b[0;36mxLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m x_original \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 29\u001b[0m      x \u001b[38;5;241m=\u001b[39m l(x) \u001b[38;5;241m+\u001b[39m x_original\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\min\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\min\\Documents\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\models\\xlstm\\sLSTMblock.py:54\u001b[0m, in \u001b[0;36msLSTMblock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m---> 54\u001b[0m     x_conv \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msilu( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv( x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) )\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) ) )\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# start sLSTM\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     ht_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mht_1\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import torch\n",
    "import processing\n",
    "import configs.common as cc\n",
    "model_type = 'xlstm'\n",
    "model = train.new_model(model_type)\n",
    "train_dataloader, test_dataloader = processing.get_train_test_dataloaders('..\\\\dataset\\\\np_dataset')\n",
    "metadata_vocab_size = processing.get_metadata_vocab_size()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cc.config.values.learning_rate)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = cc.config.values.epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "        output = model(src.float())\n",
    "        output = output.reshape(-1, model.vocab_size)  # Flatten the output to [batch_size * seq_len, vocab_size]\n",
    "        trg = trg.view(-1)  # Flatten the target to [batch_size * seq_len]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, metadata in test_dataloader:\n",
    "            src, trg = src, trg\n",
    "            output = model(src)\n",
    "            output = output.reshape(-1, model.vocab_size)\n",
    "            trg = trg.view(-1)\n",
    "            val_loss += criterion(output, trg).item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.9027e-02, -6.5153e-02, -7.2500e-02,  ...,  2.3825e-01,\n",
       "          -6.5157e-03, -7.2104e-04],\n",
       "         [-7.4015e-02,  8.5847e-03, -8.6271e-03,  ..., -4.3834e-02,\n",
       "          -6.0125e-02,  1.3329e-01],\n",
       "         [ 1.8839e-01,  1.6753e-01,  1.2251e-01,  ..., -3.4827e-02,\n",
       "          -6.5553e-02, -5.6386e-02],\n",
       "         ...,\n",
       "         [ 9.5655e-01,  9.6815e-02, -2.6273e-01,  ...,  6.4457e-02,\n",
       "           5.0679e-01, -2.0191e-01],\n",
       "         [ 6.0297e-01, -2.0983e-01, -2.0662e-01,  ...,  1.1851e-01,\n",
       "           4.4244e-01, -1.6025e-01],\n",
       "         [-5.3179e-02,  8.7127e-02, -9.3752e-02,  ...,  5.9002e-01,\n",
       "           3.9868e-01, -4.1369e-02]],\n",
       "\n",
       "        [[ 5.6037e-03,  2.9015e-02, -5.0691e-02,  ...,  5.8675e-02,\n",
       "           1.0559e-01,  4.9357e-02],\n",
       "         [ 1.4903e-01,  3.4690e-02, -1.2088e-01,  ..., -5.1628e-02,\n",
       "          -3.0116e-02, -1.3277e-01],\n",
       "         [-1.2580e-01, -1.4506e-01,  9.8312e-02,  ..., -2.1266e-01,\n",
       "          -2.0533e-01, -1.1790e-01],\n",
       "         ...,\n",
       "         [ 7.5295e-02, -2.0853e-01, -2.7807e-01,  ..., -3.1920e-02,\n",
       "          -1.4839e-01, -1.0251e-01],\n",
       "         [-3.2431e-02,  3.0798e-01, -2.5865e-01,  ...,  4.9896e-02,\n",
       "           7.7700e-02,  4.6098e-02],\n",
       "         [ 5.8692e-01,  1.2095e+00,  1.7967e-01,  ..., -1.6302e-01,\n",
       "          -1.9450e-01, -8.6801e-02]],\n",
       "\n",
       "        [[ 5.9247e-02, -2.0728e-02, -7.7756e-02,  ..., -2.7939e-02,\n",
       "          -2.7600e-02,  2.2043e-02],\n",
       "         [-2.5740e-02,  2.3503e-01, -1.6014e-01,  ...,  9.6991e-02,\n",
       "           7.8665e-02,  4.7433e-02],\n",
       "         [ 2.9091e-02, -9.3018e-02, -2.0028e-01,  ..., -2.9591e-02,\n",
       "          -2.6600e-01,  7.3231e-02],\n",
       "         ...,\n",
       "         [ 8.3259e-01,  1.0580e+00, -2.7701e-01,  ..., -6.6059e-02,\n",
       "          -1.1180e-02, -1.5424e-02],\n",
       "         [-1.8028e-01,  8.7821e-03,  4.0288e-02,  ...,  3.3329e-01,\n",
       "          -2.7770e-01,  3.1839e-01],\n",
       "         [ 3.0490e-01,  6.9092e-02,  2.9118e-01,  ...,  8.6602e-01,\n",
       "          -0.0000e+00, -4.5612e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-7.2572e-02, -7.2032e-03,  9.7106e-02,  ..., -8.9234e-02,\n",
       "           5.9425e-02, -6.2112e-02],\n",
       "         [ 1.5831e-01, -7.5803e-02, -1.0783e-01,  ..., -1.3120e-01,\n",
       "          -1.7452e-01,  1.8929e-02],\n",
       "         [-1.4507e-01,  9.1937e-02,  1.3945e-01,  ...,  2.3760e-01,\n",
       "           3.2583e-01,  1.4140e-01],\n",
       "         ...,\n",
       "         [ 3.5465e-02, -2.3918e-01, -2.1504e-01,  ..., -9.4916e-02,\n",
       "           2.9526e-01,  8.3187e-02],\n",
       "         [-2.3773e-01, -2.0021e-01, -2.2191e-01,  ...,  3.4860e-01,\n",
       "          -1.3639e-01,  6.5828e-01],\n",
       "         [-7.8370e-02,  2.5319e-01,  7.6116e-03,  ...,  5.8308e-01,\n",
       "          -4.3085e-02, -1.2868e-01]],\n",
       "\n",
       "        [[-1.6765e-01,  6.8829e-02, -9.2210e-03,  ...,  8.5718e-02,\n",
       "           1.0513e-01, -9.8810e-02],\n",
       "         [-9.3687e-02,  1.2349e-01, -8.1320e-03,  ...,  1.1575e-02,\n",
       "           1.4182e-01, -5.9578e-02],\n",
       "         [ 9.7940e-03, -8.8798e-02, -4.7618e-02,  ..., -5.9338e-02,\n",
       "           3.9292e-03,  2.7521e-02],\n",
       "         ...,\n",
       "         [-2.7650e-01, -2.6479e-01, -2.7846e-01,  ..., -7.7366e-03,\n",
       "           1.0925e-01, -9.1933e-02],\n",
       "         [ 0.0000e+00, -2.0874e-02, -1.1345e-01,  ..., -4.1558e-02,\n",
       "          -3.5867e-02,  5.3011e-01],\n",
       "         [-8.9551e-02,  1.1476e-01, -2.4806e-01,  ...,  1.4195e-01,\n",
       "          -1.2491e-01,  1.9258e-02]],\n",
       "\n",
       "        [[-6.4729e-03, -1.6472e-01, -4.3043e-02,  ..., -6.8225e-02,\n",
       "          -8.5381e-03, -5.3887e-02],\n",
       "         [-3.2819e-03,  3.6544e-03, -8.8615e-03,  ..., -3.8316e-02,\n",
       "          -6.3408e-02,  2.2834e-02],\n",
       "         [ 1.3371e-02,  2.3260e-01,  2.3800e-01,  ...,  4.0777e-03,\n",
       "           1.6704e-01, -2.4552e-02],\n",
       "         ...,\n",
       "         [-1.2383e-01, -7.1396e-02,  4.2366e-01,  ..., -1.7138e-01,\n",
       "          -2.2081e-01,  5.9848e-02],\n",
       "         [ 9.8369e-01, -1.8659e-01,  1.8367e-01,  ..., -1.5221e-01,\n",
       "           3.2192e-01,  2.6977e-01],\n",
       "         [-1.8966e-01,  4.5405e-01, -4.5190e-02,  ..., -2.6764e-01,\n",
       "          -6.0588e-02, -2.7229e-01]]], grad_fn=<SiluBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.xlstm.utils import BlockDiagonal, CausalConv1D\n",
    "x = torch.randn(8, 128, 128) \n",
    "ln = nn.LayerNorm(128)\n",
    "x = ln(x.float())\n",
    "\n",
    "conv = CausalConv1D(128, 128, int(128/8))\n",
    "drop = nn.Dropout(0.01)\n",
    "F.silu( drop(conv( x.transpose(1, 2) ).transpose(1, 2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(block_size=252,\n",
       "          n_embd=128,\n",
       "          n_head=8,\n",
       "          n_layer=8,\n",
       "          feedforward_dim=2048,\n",
       "          vocab_size=835,\n",
       "          block_len=128,\n",
       "          device='cpu',\n",
       "          metadata_dims=namespace(composer=8),\n",
       "          dropout=0.01,\n",
       "          epochs=200,\n",
       "          eval_interval=100,\n",
       "          save_interval=500,\n",
       "          learning_rate=0.1,\n",
       "          eval_iters=200,\n",
       "          test_ratio=0.2,\n",
       "          batch_size=8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.get_xlstm_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
