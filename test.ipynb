{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import processing\n",
    "import models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Get_Ready_for_This.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Here_I_Go.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Let_the_Beat_Control_Your_Body.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Let_the_Beat_Control_Your_Body.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Let_the_Beat_Control_Your_Body.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Let_the_Beat_Control_Your_Body.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Maximum_Overdrive.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Maximum_Overdrive.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_Limit.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_Limit.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_Limit.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_Limits.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_Limit_extended_.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_One.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\No_One.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\The_Real_Thing.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\The_Real_Thing.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\The_Real_Thing.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Tribal_Dance_edit_.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Tribal_Dance_edit_.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Tribal_Dance_edit_.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Twilight_Zone.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Twilight_Zone.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Twilight_Zone.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Twilight_Zone.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Workaholic.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\2_Unlimited\\Workaholic.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Andra_tutto_bene_58_.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Andra_tutto_bene_58_.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Chiuditi_nel_cesso.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Chiuditi_nel_cesso.mid]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Draco\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [F:\\GitHub\\dataset\\midi_dataset\\883\\Come_mai_feat._Fiorello_.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Come_mai_feat._Fiorello_.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Come_mai_feat._Fiorello_.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Con_un_deca.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Con_un_deca.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Cumuni.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Dimmi_perche_remix_.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Gli_anni_96_.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Gli_anni_96_.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Grazie_mille.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Grazie_mille.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Hanno_ucciso_luomo_ragno.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Hanno_ucciso_luomo_ragno.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Hanno_ucciso_luomo_ragno.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Innamorare_tanto.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Io_ci_saro.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Io_ci_saro.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\La_dura_legge_del_gol.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\La_regola_dellamico.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Le_luci_di_Natale.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nella_notte.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nella_notte.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nella_notte.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nella_notte_Molella_remix_.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nessun_rimpianto.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nessun_rimpianto.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Non_mi_arrendo.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Non_mi_arrendo.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Non_ti_passa_piu.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nord_Sud_Ovest_Est.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nord_Sud_Ovest_Est.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nord_Sud_Ovest_Est.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nord_Sud_Ovest_Est.4.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Nord_Sud_Ovest_Est.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Rotta_x_casa_di_Dio.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Sei_un_mito.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Sei_un_mito.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Sei_un_mito.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Sei_un_mito.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Senza_averti_qui.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Senza_averti_qui.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Senza_averti_qui.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Se_tornerai.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Se_tornerai.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Se_tornerai.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Tieni_il_tempo.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Tieni_il_tempo.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Tieni_il_tempo.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Ti_sento_vivere.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Tutto_cio_che_ho.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Una_canzone_damore.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Una_canzone_damore.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Una_canzone_damore.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Un_giorno_cosi.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Un_giorno_cosi.mid] [F:\\GitHub\\dataset\\midi_dataset\\883\\Viaggio_al_centro_del_mondo.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Andante,_Andante.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Angeleyes.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Another_Town,_Another_Train.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Chiquitita.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Chiquitita.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Chiquitita.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Chiquitita.4.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Chiquitita.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dance_While_the_Music_Still_Goes_on_.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dance_While_the_Music_Still_Goes_on_.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dance_While_the_Music_Still_Goes_on_.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dance_While_the_Music_Still_Goes_on_.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.10.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.11.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.12.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.4.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.5.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.6.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.7.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.8.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.9.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Dancing_Queen.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Does_Your_Mother_Know.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Does_Your_Mother_Know.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Does_Your_Mother_Know.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Does_Your_Mother_Know.4.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Does_Your_Mother_Know.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Eagle.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.10.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.11.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.2.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.3.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.4.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.5.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.6.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.7.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.8.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.9.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Fernando.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Gimme_Gimme_Gimme.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Gimme_Gimme_Gimme.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Hamlet_III,_Part_2.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Hasta_Manana.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Hey,_Hey_Helen.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Hey,_Hey_Helen.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Hole_In_Your_Soul.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Honey_Honey.1.mid] [F:\\GitHub\\dataset\\midi_dataset\\ABBA\\Honey_Honey.mid]"
     ]
    }
   ],
   "source": [
    "processing.preprocess_midi_files('F:\\\\GitHub\\\\dataset\\\\midi_dataset', 'F:\\\\GitHub\\\\dataset\\\\np_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = processing.get_train_test_dataloaders('F:\\\\GitHub\\\\dataset\\\\np_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SequenceDataset.data_augementation() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m     13\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 15\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(output.shape)\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Reshape output and target for loss calculation\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mf:\\GitHub\\Deep-Learning-Based-Sequence-Models-for-Music-Generation\\processing\\dataset.py:165\u001b[0m, in \u001b[0;36mSequenceDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    162\u001b[0m         sequence \u001b[38;5;241m=\u001b[39m sequence[ix: ix \u001b[38;5;241m+\u001b[39m seq_len_extra]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# sequence = torch.tensor(sequence, device=DEVICE)\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_augementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Fetch metadata for the band\u001b[39;00m\n\u001b[0;32m    168\u001b[0m path_parts \u001b[38;5;241m=\u001b[39m Path(file_path)\u001b[38;5;241m.\u001b[39mparts\n",
      "\u001b[1;31mTypeError\u001b[0m: SequenceDataset.data_augementation() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "with open('F:\\\\GitHub\\\\dataset\\\\midi_dataset\\\\tokenizations.json', 'r') as f:\n",
    "    tokenizations = json.load(f)\n",
    "METADATA_VOCAB_SIZE = tokenizations['VOCAB_SIZE']\n",
    "model = models.SimpleTransformer(VOCAB_SIZE, METADATA_VOCAB_SIZE, N_EMBD, N_HEAD, N_LAYER, FEEDFORWARD_DIM, BLOCK_SIZE, DROPOUT, DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = EPOCHS\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "        # Forward pass\n",
    "        output = model(src, metadata)\n",
    "        # print(output.shape)\n",
    "        # Reshape output and target for loss calculation\n",
    "        output = output.reshape(-1, VOCAB_SIZE)  # Flatten the output to [batch_size * seq_len, vocab_size]\n",
    "        trg = trg.view(-1)  # Flatten the target to [batch_size * seq_len]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Validation loop (optional)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, metadata in test_dataloader:\n",
    "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "            output = model(src, metadata)\n",
    "            output = output.reshape(-1, VOCAB_SIZE)\n",
    "            trg = trg.view(-1)\n",
    "            val_loss += criterion(output, trg).item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        ...,\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n",
      "tensor([[258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        ...,\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n",
      "tensor([[258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        ...,\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n",
      "tensor([[258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        ...,\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n",
      "tensor([[258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        ...,\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n",
      "tensor([[258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "        # Forward pass\n",
    "        output = model(src, metadata)\n",
    "        print(output.argmax(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 985 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flattened_tensor = src.flatten()\n",
    "bins = VOCAB_SIZE\n",
    "hist = torch.histc(flattened_tensor.int(), bins=bins, min=0, max=VOCAB_SIZE)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(bins), hist.cpu().int().numpy(), width=1, align='center', color='blue', edgecolor='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (src, trg, metadata) in enumerate(train_dataloader):\n",
    "    print(src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PITCH_RES': 1, 'DYN_RES': 129, 'LENGTH_RES': 257, 'TIME_RES': 457, 'CHANNEL_RES': 557, 'TEMPO_RES': 685}\n"
     ]
    }
   ],
   "source": [
    "print(START_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size, metadata_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout, device = VOCAB_SIZE, METADATA_VOCAB_SIZE, N_EMBD, N_HEAD, N_LAYER, FEEDFORWARD_DIM, BLOCK_SIZE, DROPOUT, DEVICE\n",
    "embedding = nn.Embedding(src_vocab_size, d_model).to(device)\n",
    "metadata_embedding = nn.Embedding(metadata_vocab_size, d_model).to(device)  # Metadata embedding layer\n",
    "positional_encoding = models.PositionalEncoding(d_model, max_len, device)\n",
    "layers = nn.ModuleList([models.TransformerBlock(d_model, num_heads, d_ff, dropout).to(device) for _ in range(num_layers)])  # Adjust for concatenated embeddings\n",
    "fc_out = nn.Linear(d_model, src_vocab_size).to(device)  # Adjust for concatenated embeddings\n",
    "dropout = nn.Dropout(dropout).to(device)\n",
    "max_len = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src.to(device)\n",
    "# start_idx = [self.get_idx(x) for x in src[:, 0]]\n",
    "metadata = metadata.to(device)\n",
    "# Embed the input sequence\n",
    "src_emb = embedding(src)  # Shape: [batch_size, seq_len, d_model]\n",
    "src_emb = positional_encoding(src_emb)  # Shape: [batch_size, seq_len, d_model]\n",
    "metadata_emb = metadata_embedding(metadata)  # Shape: [batch_size, 6, d_model]\n",
    "\n",
    "# x = torch.cat([metadata_emb, src_emb], dim=-2)  # Shape: [batch_size, seq_len + 6, d_model]\n",
    "# x = self.dropout(src_emb)\n",
    "x = src_emb\n",
    "\n",
    "# Pass through transformer layers\n",
    "for layer in layers:\n",
    "    x = layer(x, None)\n",
    "\n",
    "# Final output layer\n",
    "out = fc_out(x)  # Shape: [batch_size, seq_len, src_vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[545, 471, 702,  ..., 892, 485,  89]],\n",
       "\n",
       "        [[636, 330, 718,  ..., 545,  19, 419]],\n",
       "\n",
       "        [[139, 539, 666,  ..., 300, 942, 700]],\n",
       "\n",
       "        [[297,  48, 601,  ..., 636,  23, 277]]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.argmax(2).unsqueeze(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "torch.Size([4, 256])\n",
      "tensor([[258, 258, 258,  ..., 259, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258],\n",
      "        [258, 258, 258,  ..., 258, 258, 258]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 9])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(src, metadata)\n",
    "print(trg.shape)\n",
    "print(src.shape)\n",
    "print(output.argmax(dim=2))\n",
    "idx = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 9, 8], [0, 1, 2, 3, 4, 5, 6, 7, 9, 8], [0, 1, 2, 3, 4, 5, 6, 7, 9, 11]])\n",
    "idx.argmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
