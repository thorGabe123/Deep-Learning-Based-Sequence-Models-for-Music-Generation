{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268131de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import processing\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d58949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.csv' with your actual file path\n",
    "df = pd.read_csv('E:\\\\GitHub\\\\dataset\\\\classical piano midi\\\\full_music_pieces_youtube_similarity_pianosoloprob_split.csv', sep='\t')\n",
    "\n",
    "# Create unique tokens\n",
    "tokens = sorted(set(f\"{row['surname']}, {row['firstname']}\" for _, row in df.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d687b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_paths = list(processing.find_files_by_extensions('E:\\\\GitHub\\\\dataset\\\\classical piano midi', ['.mid', '.midi']))\n",
    "all_composers = []\n",
    "for path in midi_paths:\n",
    "    path_parts = Path(path).parts\n",
    "    match = re.match(r'^([^,]*,[^,]*)', path_parts[-1])\n",
    "    all_composers.append(match[0])\n",
    "band_json = {name: idx for idx, name in enumerate(sorted(set(all_composers)), start=3)}\n",
    "band_json[\"null\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6fa0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "tokenized_json = {\n",
    "    \"genre_tokenized\" : {\n",
    "        \"Classical\" : 0\n",
    "    },\n",
    "    \"time_tokenized\" : {\n",
    "        1800 : 1\n",
    "    },\n",
    "    \"band_tokenized\" : band_json\n",
    "}\n",
    "output_path = 'E:\\\\GitHub\\\\dataset\\\\tokenization.json'\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(tokenized_json, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b773db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_path = 'E:\\\\GitHub\\\\dataset\\\\tokenization.json'\n",
    "\n",
    "# tokenized_json[\"band_tokenized\"]\n",
    "with open(output_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8563c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = {\n",
    "    \"artists\": []\n",
    "}\n",
    "for band in data[\"band_tokenized\"]:\n",
    "    meta_dict['artists'].append({\n",
    "      \"name\": band,\n",
    "      \"year_started\": 1800,\n",
    "      \"genres\": [\"Classical\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "595b53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'E:\\\\GitHub\\\\dataset\\\\metadata.json'\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(meta_dict, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
